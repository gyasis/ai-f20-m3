{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time the cells \n",
    "%load_ext autotime\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cluster import Kmeans \n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('Databank/collection/Train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Survived  Pclass  \\\n",
       "0           0         0       3   \n",
       "1           1         1       1   \n",
       "2           2         1       3   \n",
       "3           3         1       1   \n",
       "4           4         0       3   \n",
       "\n",
       "                                                Name  Sex       Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    1 -0.565736      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  0.663861      1   \n",
       "2                             Heikkinen, Miss. Laina    0 -0.258337      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  0.433312      1   \n",
       "4                           Allen, Mr. William Henry    1  0.433312      0   \n",
       "\n",
       "   Parch      Fare  Embarked  Deck  Cabin_NR  relatives  not_alone  Title  \n",
       "0      0 -0.502445         2     7       NaN          1          0      1  \n",
       "1      0  0.786845         0     2      85.0          1          0      3  \n",
       "2      0 -0.488854         2     7       NaN          0          1      2  \n",
       "3      0  0.420730         2     2     123.0          1          0      3  \n",
       "4      0 -0.486337         2     7       NaN          0          1      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Deck</th>\n      <th>Cabin_NR</th>\n      <th>relatives</th>\n      <th>not_alone</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>1</td>\n      <td>-0.565736</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.502445</td>\n      <td>2</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>0</td>\n      <td>0.663861</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.786845</td>\n      <td>0</td>\n      <td>2</td>\n      <td>85.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>0</td>\n      <td>-0.258337</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.488854</td>\n      <td>2</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>0</td>\n      <td>0.433312</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.420730</td>\n      <td>2</td>\n      <td>2</td>\n      <td>123.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>1</td>\n      <td>0.433312</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.486337</td>\n      <td>2</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Name','Cabin_NR','Survived'], axis=1)\n",
    "y = data.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "  models = [\n",
    "          ('LogReg', LogisticRegression()), \n",
    "          ('RF', RandomForestClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('SVM', SVC()), \n",
    "          ('GNB', GaussianNB())\n",
    "        \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='poly')\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "sv = svclassifier.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "y_prediction = svclassifier.predict(X_test)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[93 17]\n [19 50]]\n              precision    recall  f1-score   support\n\n           0       0.83      0.85      0.84       110\n           1       0.75      0.72      0.74        69\n\n    accuracy                           0.80       179\n   macro avg       0.79      0.79      0.79       179\nweighted avg       0.80      0.80      0.80       179\n\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_prediction))\n",
    "print(classification_report(y_test,y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.48044692737430167\n",
      "0.6145251396648045\n",
      "0.6145251396648045\n",
      "0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "for kernel in ('sigmoid','poly','rbf', 'linear'):\n",
    "        svclassifier = SVC(kernel=kernel)\n",
    "        sv = svclassifier.fit(X_train, y_train)\n",
    "        # print(sv.score(X_train, y_train))\n",
    "        y_prediction = svclassifier.predict(X_test)\n",
    "        # print(confusion_matrix(y_test,y_prediction))\n",
    "        # print(classification_report(y_test,y_prediction))\n",
    "\n",
    "        # same as yours...\n",
    "\n",
    "\n",
    "        # get the accuracy\n",
    "        print(accuracy_score(y_test, y_prediction))\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d5fd5d3c1236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':[0.1, 1, 10, 100], 'gamma': [1,0.1,0.01,0.001], 'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=5)\n",
    "\n",
    "y = y_train\n",
    "y = y.values.ravel()\n",
    "grid.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuickScores():\n",
    "    scores= []\n",
    "\n",
    "    for kernel in ('sigmoid','poly','rbf', 'linear'):\n",
    "        svclassifier = SVC(kernel=kernel)\n",
    "        sv = svclassifier.fit(X_train, y_train)\n",
    "        # print(sv.score(X_train, y_train))\n",
    "        y_prediction = svclassifier.predict(X_test)\n",
    "\n",
    "        #this should be its own functoin\n",
    "        # print(confusion_matrix(y_test,y_prediction))\n",
    "        # print(classification_report(y_test,y_prediction))\n",
    "        # get the accuracy\n",
    "        score = (X_test,y_test) \n",
    "        scores = scores.append(score)\n",
    "\n",
    "\n",
    "    lor = LogisticRegression()\n",
    "    lor.fit(X_train,y_train)\n",
    "    score = lor.score(X_test, y_test)\n",
    "    print(score)\n",
    "    scores = scores.append(score)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    lr.score(X_test, y_test)\n",
    "    scores = scores.append(score)\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train,y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "    scores = scores.append(score)\n",
    "\n",
    "\n",
    "    kn = KNeighborsClassifier()\n",
    "    kn.fit(X_train, y_train)\n",
    "    kn.score(X_test, y_test)\n",
    "    scores = scores.append(score)\n",
    "\n",
    "    gb = GaussianNB()\n",
    "    gb.fit(X_train, y_train)\n",
    "    gb.score(X_test, y_test)\n",
    "    scores = scores.append()\n",
    "\n",
    "    gbr = GradientBoostingRegressor(random_state=0)\n",
    "    gbr.fit(X_train, y_train)\n",
    "    gbr.score(X_test, y_test)\n",
    "    scores = scores.append()\n",
    "\n",
    "    \n",
    "\n",
    "    pca = PCA(n_components=8)\n",
    "    pca.fit(X_train, y_train)\n",
    "    pca.score(X, y)\n",
    "    scores = scores.append()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "lor = LogisticRegression()\n",
    "lor.fit(X_train,y_train)\n",
    "score = lor.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.399899056784068"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "rf.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8379888268156425"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, y_train)\n",
    "kn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "gb = GaussianNB()\n",
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4680460396845043"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "gbr.fit(X_train, y_train)\n",
    "gbr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-18.955823194992362"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "pca = PCA(n_components=8)\n",
    "pca.fit(X_train, y_train)\n",
    "pca.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "kmeans.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}